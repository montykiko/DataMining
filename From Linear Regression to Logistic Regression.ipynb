{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnXnxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c06dba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure()\n",
    "plt.axis([-6,6,0,1])\n",
    "plt.grid(True)\n",
    "X = np.arange(-6,6,0.1)\n",
    "y = 1/(1 + np.e ** (-X))\n",
    "plt.plot(X,y,'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 垃圾短信分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/machine-learning-databases/00228/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./some datasets/SMSSpamCollection',delimiter='\\t',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[0]=='spam'][0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[0]=='ham'][0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./some datasets/SMSSpamCollection',delimiter='\\t',header=None)\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(df[1],df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类型：ham. 信息：Haiyoh... Maybe your hamster was jealous of million\n",
      "预测类型：ham. 信息：Yes :)it completely in out of form:)clark also utter waste.\n",
      "预测类型：ham. 信息：Probably money worries. Things are coming due and i have several outstanding invoices for work i did two and three months ago.\n",
      "预测类型：ham. 信息：I can probably come by, everybody's done around  &lt;#&gt;  right?\n",
      "预测类型：ham. 信息：I'm at bruce &amp; fowler now but I'm in my mom's car so I can't park (long story)\n"
     ]
    }
   ],
   "source": [
    "for i,prediction in enumerate(predictions[-5:]):\n",
    "    print('预测类型：%s. 信息：%s' %(prediction,X_test_raw.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二元分类效果评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngf4LyGG2M2eKDU8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111ef6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAD3CAYAAAAOh6G5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGA1JREFUeJzt3X2wXXV97/H3hxAJEB6EoEBIGqtRq9zyFIHCTEutRUAU\n2qEVnxgRzQWfr6iDSkFtre11rvUyUWMUilEulSo4FMJEfCrg8BxDJIAY7AUCuYaABsKTcM7n/rHW\nqZvTs9de55y9z9rn7M9rZg17rfXbv/Xbm5zv/j2t35JtIiLa2a7pAkREf0uQiIhKCRIRUSlBIiIq\nJUhERKUEiYiolCARMcNImiXpp5KuGOOcJJ0naYOkdZIO7pRfgkTEzPMB4M42544FFpfbUuDLnTJL\nkIiYQSTtB7wO+FqbJCcAK124Adhd0j5VeSZINEjSjpL+TdJWSf86iXzeIul73Sxb0yQtlLRN0qym\nyzLNfAH4KDDc5vx84P6W/Y3lsba27065Zj5JbwY+BLwceAxYC3zG9nWTyPYk4IXAnrafnWgmti8C\nLppEOaaUpP8LvNP299ulsX0fMHfKCtWQ1/7pzn74kaFaaW9d9/R64KmWQytsrxjZkXQ8sNn2rZKO\n6lYZEyRqkPQh4CzgdGA18FvgtcAbgMkEid8D7p5MgJiJJG0/KN/JlkeGuHH1frXSzt7nnqdsL6lI\nciTwBknHAXOAXSV90/ZbW9I8ACxo2d+vPNZWmhsdSNoN+DTwHtuX2n7c9jO2r7D9UUk7SPqCpAfL\n7QuSdijfe5SkjZLOlLRZ0iZJp5bnPgWcA7yxrFafJumTkr7Zcu1Fkixp+3L/7ZJ+KekxSf8h6S0t\nx69red8Rkm4umzE3Szqi5dyPJf2tpJ+U+XxP0rwO38FIOU6VdL+kX0s6XdKryh7y30ha1pL+xZJ+\nKOlhSVskXSRp9/LcN4CFwL+Vn/ujLfmfJuk+4Ietn13SHuX3+Poyj7ll7/wpk/qf2xfMkIdrbR1z\nsj9mez/bi4CTgR+OChAAlwOnlKMchwNbbW+qyjdBorM/oojKl7U5/wngcOBA4ADgUODslvN7A7tR\ntPtOA74o6fm2zwX+HviW7bm2z68qhKSdgfOAY23vAhxB0eQZnW4P4Moy7Z7A54ErJe3ZkuzNwKnA\nC4DnAR+uunaLwyh6xd9I0fb9BPAa4JXAX0v6k5FiAJ8F9gX+gOKX65MAtt8G3Ae8vvzc/7Ml/z8p\n07+29aK2HwHeAXxV0guAfwLW2l5Zs9x9y8AwrrVNVBnQTy93VwG/BDYAXwXe3en9aW50tiewpaL6\n+xbgfbY3w3/WEL4C/E15/hng0+X7V0naBrwMuGECZRkG9pd0Xxn9x/oFeB3wC9vfKPcvlvR+4PXA\nheWxf7Z9d1neSyiaTXX8re2ngO9Jehy4uOVzXwscBPy77Q0U/wgBHpL0eeDcGvl/0vbjZX7POWH7\ne2Xn7g+APYA/rFnmvmbMM67XJzGufO0fAz8uXy9vOW7gPePJKzWJzh4G5o1U+cewL3Bvy/695bH/\nfP+oAPMEE+iQK/943kjRL7JJ0pWSXl6jPCNlau3B/n8TLM+vWl4/Ocb+XABJL5T0L5IekPQo8E2g\nsklTur/D+RXA/sCFth+uWea+1+uaxGQlSHR2PfA0cGLrQUnHSPo5RW2stbq+EHhwgtd6HNipZX/v\n1pO2V9v+c2Af4C6K6uJoD1J0iLZaSIfOqS77e4qa9H+zvSvwVoomyIh2/+Jbj480Q9ZCMYuQIkis\nBN4t6SVdLXFDDAzhWltTEiQ6sL2VooPxi5JOlLRT2TF5AUV17nMU7fEjyw7Acyh+OSdiLfDH5RyB\n3YCPjZwof51PKPsmnga2MfZY+CrgpZLeXHb6vRF4BfBfpuj20C5l+bZKmg98ZNT5XwG/3yGPb4/a\n/zjF39Q7KL7zlZohcyhSk5gBbP8vijkSZwMPUfxazwa+TjHysRa4CvgZsAb4uwle52rgW8A64Fae\n+4e9XVmGB4FHKDr5zhgjj4eB44EzKZpKHwWOt71lImWaoE8BBwNbKTpRLx11/rPA2eWoSLtO05tG\nXkg6hOKzn2J7CPhHioBxVrcLPtUMDNm1tqYoa1yOn6STgGNsv7PcfxtwmO33NluymUXSIuAK2/s3\nXJSeOeCA5/mqVXW6a2D+fptu7TBPoicyuhHRIDfc31BHmhsTM+5Za/1Oxf0f28bY1jddtpnMhmdq\nbk1JTWJibgYWS3oRRXA4mWKC0rQ13e7/mDnEEOqcrEGpSUxAOe/hvRT3cdwJXGI7v7hdJOliiuHn\nl5VTsk9ruky9YGDY9bampCYxQbZXUQw3Rg/YflPTZZgq/V6TSJCIaFAxmSpBIiIqDDtBIiLaSE0i\nIioZ8Yz7e3Z5RjcmQdLSpssw083073ikJlFna0qCxOTM6H/AfWKGf8diyNvV2pqS5kZEg4qVqfr7\nt7qvgsS8PWZ50YLZTRejtoXzt2fJAXP6e+L9KHev26lzoj4yh53YVXtMq+/4KR7nt366dvsgHZfj\nsGjBbG5avaBzwpiw1+57YNNFmPFu9A9qp7XVaFOijr4KEhGDaDg1iYhox4jfur//DPu7dBEzXDou\nI6KjoUzLjoh2jBhKTSIiqgxndCMi2immZSdIREQb0+EGrwSJiAbZ9P1kqv4uXcSMJ4Zrbh1zkuZI\nuknSbZLWlw+vHp3mKElbJa0tt3M65ZuaRESDiid4de23+mng1ba3SZoNXCfpKtujn2B/re3j62aa\nIBHRsG51XLp4HN+2cnd2uU365rg0NyIaZMSw6211SJolaS2wGbja9o1jJDtC0jpJV0l6Zac8U5OI\naNg4ahLzJN3Ssr/C9orWBOUDlQ+UtDtwmaT9bd/ekmQNsLBskhwHfBdYXHXRBImIBo1zCHRL3QcG\n2/6NpB8BxwC3txx/tOX1KklfkjSv6qnzaW5ENKh4gtd2tbZOJO1V1iCQtCPw58Bdo9LsLUnl60Mp\nYsDDVfmmJhHRsC6uTLUP8HVJsyj++C+xfYWk0wFsLwdOAs6Q9CzwJHBy2eHZVoJERINsde3eDdvr\ngIPGOL685fUyYNl48k2QiGhYv8+4TJCIaFCx6EzWk4iItrIQbkRUMOQu0Ihob2TGZT9LkIhoWBbC\njYi2ivUkUpOIiAppbkREW0WfRJobEVEhDwyOiLaMeHY4Q6ARUSEzLiOirYxuRERH6biMiLYy4zIi\nOkqfRES0VSxflyAREe04Q6ARUSGLzkRER2luRERb06FPoqcDtJKOkfRzSRskndXLa0VMV918zF8v\n9KwmUa79/0WKB4RsBG6WdLntO3p1zYjpZtDnSRwKbLD9SwBJ/wKcACRIRIwwPDvAMy7nA/e37G8E\nDuvh9SKmnenQJ9F4x6WkpcBSgIXzGy9OxJTr9yDRy3rOA8CClv39ymPPYXuF7SW2l+y1Z39PKono\ntpE+iX7uuOxlkLgZWCzpRZKeB5wMXN7D60VMS7ZqbU3pWf3e9rOS3gusBmYBF9he36vrRUxXAz3j\n0vYqYFUvrxExndnd65OQNAe4BtiB4m/727bPHZVGwP8GjgOeAN5ue01VvukpjGiUGBruWqv/aeDV\ntrdJmg1cJ+kq2ze0pDkWWFxuhwFfpsOoY4JERMO61d9g28C2cnd2uXlUshOAlWXaGyTtLmkf25va\n5dvfszgiZriReRI1RzfmSbqlZVs6Oj9JsyStBTYDV9u+cVSSseYvza8qY2oSEU1y0S9R0xbbSyqz\ns4eAAyXtDlwmaX/bt0+miKlJRDRsGNXaxsP2b4AfAceMOlVr/lKrBImIBpnuzZOQtFdZg0DSjhQ3\nV941KtnlwCkqHA5sreqPgDQ3IhrW1dmU+wBfL+/A3g64xPYVkk4HsL2cYkrCccAGiiHQUztlmiAR\n0bDh4a6NbqwDDhrj+PKW1wbeM558EyQiGmR3bwi0VxIkIhrW73eBJkhENGwcQ6CNSJCIaFiaGxHR\nlmn2NvA6EiQiGtbnrY0EiYhGGdylIdBeSZCIaNi0bW5I2rXqjbYf7X5xIgbPdB7dWE/RXGoNcyP7\nBhb2sFwRA2Hk3o1+1jZI2F7Q7lxEdImBPg8Ste4ClXSypI+Xr/eTdEhvixUxOOx6W1M6BglJy4A/\nBd5WHnoCWN7+HRExLq65NaTO6MYRtg+W9FMA24+Uz9GIiEnTjBgCfUbSdpSxTNKewHBPSxUxKKbB\nXaB1+iS+CHwH2EvSp4DrgH/saakiBsl0b27YXinpVuA15aG/muzCmhHRqr9rEnVnXM4CnqGIZ1kX\nM6Kb+nwyVZ3RjU8AFwP7Uqys+38kfazXBYsYGNO9uQGcAhxk+wkASZ8Bfgp8tpcFixgIM+QGr02j\n0m1fHouIbujz5kbVDV7/RFH8R4D1klaX+0cDN09N8SIGQJ8PgVbVJEZGMNYDV7Ycv2GMtBExQZqu\nNQnb509lQSIGUsOdknV07JOQ9GLgM8ArgDkjx22/tIflihgQ6vvmRp05DxcC/0wx4+NY4BLgWz0s\nU8Rg6fMh0DpBYifbqwFs32P7bIpgERHdMFxza0idIdCnyxu87ikfPPoAsEtvixUxIGbIojP/A9gZ\neD9wJPAu4B29LFTEIJHrbR3zkRZI+pGkOyStl/SBMdIcJWmrpLXldk6nfOvc4HVj+fIxfrfwTER0\nS/f6G54FzrS9RtIuwK2SrrZ9x6h019o+vm6mVZOpLqOi+Lb/su5F6rrjwb045JNndDvbaDF71UNN\nF2HGG3r/dY1c1/YmytnQth+TdCcwHxgdJMalqiaxbDIZR0Q945hMNU/SLS37K2yvGDNPaRFwEHDj\nGKePkLSOon/xw7bXV120ajLVDzqVOCK6oH7H5RbbSzolkjSXYqGoD47xfJw1wELb2yQdB3wXWFyV\nX9aGiGiS6eoQqKTZFAHiItuX/pfL2Y/a3la+XgXMljSvKs8EiYiGdXF0Q8D5wJ22P98mzd5lOiQd\nShEDHq7Kt/azQCXtYPvpuukjoqbujW4cSTEC+TNJa8tjH6d82p7t5cBJwBmSngWeBE62q5/qUefe\njUMpotNuwEJJBwDvtP2+iX6SiGjRpSBh+zo6LJhpexnjHJSo09w4Dzieskpi+zaKh/VExCTVbWo0\neTt5nebGdrbvLZsxI4Z6VJ6IwdPn07LrBIn7yyaHJc0C3gfc3dtiRQyQ6b6eBHAGRZNjIfAr4Pvl\nsYjoAvX58/Dq3LuxGTh5CsoSMXga7m+oo87oxlcZo0Jke2lPShQxaKZ7kKBoXoyYA/wFcH9vihMx\ngKZ7kLD9nKXqJH2D4qHBEdEF/d7cmMi07BcBL+x2QSKiP9Xpk/g1v6sQbUfxsJ6zelmoiIHS5zWJ\nyiBR3ghyAMV95wDDneZ5R8Q4uP+HQCubG2VAWGV7qNwSICK6bQYsqb9W0kE9L0nEABLT+N4NSdvb\nfpZiCaybJd0DPE7xuWz74CkqY8TM1uf186o+iZuAg4E3TFFZIgbPNJ9xKSie2jVFZYkYTNM4SOwl\n6UPtTrZbHisixqffRzeqgsQsYC4dVrqJiEmaxjWJTbY/PWUliRhEDQ9v1tGxTyIiems6d1z+2ZSV\nImKQTdcgYfuRqSxIxKCazjWJiJgKCRIR0U7TU67rSJCIaFqCRERUSU0iIqolSEREpT4PEhNZ4zIi\nuqWLzwKVtEDSjyTdIWm9pA+MkUaSzpO0QdI6SR2XfEhNIqJp3atJPAucaXuNpF2AWyVdbfuOljTH\nAovL7TDgy+V/20pNIqJhGq63dWJ7k+015evHgDuB+aOSnQCsdOEGYHdJ+1Tlm5pERMPGMboxT9It\nLfsrbK8YM09pEcWqcjeOOjWf5z5ca2N5bFO7iyZIRDRpfHeBbrG9pFMiSXOB7wAftP3oxAtXSJCI\naFoXRzckzaYIEBfZvnSMJA8AC1r29+N3j8wYU/okIhrUzdWyy+fknA/cWbFy3OXAKeUox+HAVttt\nmxrQw5qEpAuA44HNtvfv1XUipr3u1SSOBN4G/EzS2vLYx4GFALaXA6uA44ANwBPAqZ0y7WVz40Jg\nGbCyh9eImPbUpWde2b6ODotFlQ/Yes948u1ZkLB9TdnDGhHtTIPH/KXjMqJpfT4tu/EgIWkpsBRg\n9tznN1yaiKnX73eBNj66YXuF7SW2l2w/Z+emixMx9fr8gcGN1yQiBto0WJmqZzUJSRcD1wMvk7RR\n0mm9ulbEtDaoNQnbb+pV3hEzxchkqn6W5kZEwzTc31EiQSKiSdP8MX8RMQUymSoiqqUmERFV0nEZ\nEe0Z6NINXr2SIBHRsPRJRERbmScREdXsNDciolpqEhFRLUEiIqqkJhER7RnIvRsRUSVDoBFRLaMb\nEVElfRIR0V5uFY+IKsWMy/6OEgkSEU1Lx2VEVElNIiLas/t+nkTjD+eJGHRyva1WXtIFkjZLur3N\n+aMkbZW0ttzO6ZRnahIRTetuc+NCYBmwsiLNtbaPr5thgkREk7r8VHHb10ha1L0c09yIaN7ImhKd\ntu45QtI6SVdJemWnxKlJRDSt/t//PEm3tOyvsL1inFdbAyy0vU3SccB3gcVVb0iQiGjYOIZAt9he\nMplr2X605fUqSV+SNM/2lnbvSZCIaJKBoakbApW0N/Ar25Z0KEWXw8NV70mQiGiQcFcnU0m6GDiK\nommyETgXmA1gezlwEnCGpGeBJ4GT7eoCJEhENK2LQcL2mzqcX0YxRFpbgkRE0zItOyLaMrnBKyKq\n5QaviKiWIBERbdkw3N/tjQSJiKb1d4xIkIhoWvokIqJagkREtJUneI3Pk1s2bln7lTPvbboc4zAP\naHtjTF/6StMFGLfp9x3D79VP2vXbwLuur4KE7b2aLsN4SLplsnflRbWB+I4TJCKiLQND/T28kSAR\n0SiDEyRmsvGuChTjN/O/4z5vbmSNy0notHSYpKFy2fLbJf2rpJ0meq1yKfQrytdvkHRWRdrdJb17\nAtf4pKQP1z0+Ks2Fkk4ax7UWtVv2vdUElmebXkZGN+psDUmQ6K0nbR9oe3/gt8DprSdVGPf/A9uX\n2/6HiiS7A+MOEtGQqV8Id1wSJKbOtcBLyl/Qn0taCdwOLJB0tKTrJa0paxxzASQdI+kuSWuAvxzJ\nSNLbJS0rX79Q0mWSbiu3I4B/AF5c1mI+V6b7iKSby1WSP9WS1yck3S3pOuBlnT6EpHeV+dwm6Tuj\nakevkXRLmd/xZfpZkj7Xcu3/PtkvcsZJkAhJ2wPHAj8rDy0GvmT7lcDjwNnAa2wfDNwCfEjSHOCr\nwOuBQ4C922R/HvDvtg8ADgbWA2cB95S1mI9IOrq85qHAgcAhkv5Y0iHAyeWx44BX1fg4l9p+VXm9\nO4HTWs4tKq/xOmB5+RlOA7baflWZ/7skvajGdQaDDUND9baGpOOyt3aUtLZ8fS1wPrAvcK/tG8rj\nhwOvAH4iCeB5wPXAy4H/sP0LAEnfBJaOcY1XA6cA2B4Ctkp6/qg0R5fbT8v9uRRBYxfgMttPlNe4\nvMZn2l/S31E0aeYCq1vOXWJ7GPiFpF+Wn+Fo4A9b+it2K699d41rDYY+77hMkOitJ20f2HqgDASP\ntx4Crh69NqGk57xvkgR81vZz5ltK+uAE8roQONH2bZLeTrHo6ojR/9pdXvt9tluDCd1+ytS01udB\nIs2N5t0AHCnpJQCSdpb0UuAuYJGkF5fp2i1w+gPgjPK9syTtBjxGUUsYsRp4R0tfx3xJLwCuAU6U\ntKOkXSiaNp3sAmySNBt4y6hzfyVpu7LMvw/8vLz2GWV6JL1U0s41rjMgao5sNDi6kZpEw2w/VP4i\nXyxph/Lw2bbvlrQUuFLSExTNlV3GyOIDwApJpwFDwBm2r5f0k3KI8aqyX+IPgOvLmsw24K2210j6\nFnAbsBm4uUaR/wa4EXio/G9rme4DbgJ2BU63/ZSkr1H0VaxRcfGHgBPrfTsDwOA+n0ylDkvuR0QP\n7bb9Xv6jXevFzNW//tqtTdzHkppERNP6/Ic6QSKiSSNDoH0sQSKiYc5CuBHRXhadiYgq02D5usyT\niGiah+ttNUi6QNLmdnfYljcVnidpQ3kvzcGd8kyQiGiQAQ+71lbThcAxFeePpZgWv5himv+XO2WY\nIBHRJLurNQnb1wCPVCQ5AVjpwg3A7pL2qcozfRIRDfPUDoHOB+5v2d9YHtvU7g0JEhENeoxfr/6+\nvz2vZvI5km5p2V8xFSt3JUhENMh2Vf9BLzwALGjZ36881lb6JCIGy+XAKeUox+EUCwK1bWpAahIR\nM4qkiynW+JgnaSNwLjAbwPZyYBXFKmQbgCeAUzvmmbtAI6JKmhsRUSlBIiIqJUhERKUEiYiolCAR\nEZUSJCKiUoJERFRKkIiISv8fveaWdzbjUdoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1089e8630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "y_test = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [0,1,0,0,0,0,0,1,1,1]\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('Confusion_matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred,y_true = [0,1,1,0],[1,1,1,1]\n",
    "print('Accuracy:',accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955490358995 [ 0.94976077  0.96172249  0.96291866  0.95334928  0.9497006 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "df = pd.read_csv('./some datasets/SMSSpamCollection',delimiter='\\t',header=None)\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(df[1],df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "scores = cross_val_score(classifier,X_train,y_train,cv=5)\n",
    "print(np.mean(scores),scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精确率和召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "报错解决：https://stackoverflow.com/questions/39187875/scikit-learn-script-giving-vastly-different-results-than-the-tutorial-and-gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986444392853 [ 0.98412698  0.98591549  0.975       0.98717949  1.        ]\n",
      "0.669090909091 [ 0.56363636  0.63636364  0.70909091  0.7         0.73636364]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "df = pd.read_csv('./some datasets/SMSSpamCollection',delimiter='\\t',header=None)\n",
    "encoded_labels = df[0].map(lambda x:1 if x=='spam' else 0).values\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(df[1],encoded_labels)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "precisions = cross_val_score(classifier,X_train,y_train,cv=5,scoring='precision')\n",
    "print(np.mean(precisions),precisions)\n",
    "recalls = cross_val_score(classifier,X_train,y_train,cv=5,scoring='recall')\n",
    "print(np.mean(recalls),recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算综合指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795722555156 [ 0.71676301  0.77348066  0.82105263  0.81914894  0.84816754]\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(classifier,X_train,y_train,cv=5,scoring='f1')\n",
    "print(np.mean(f1s),f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ROC和AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fca6b8d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "df = pd.read_csv(r\"./some datasets/SMSSpamCollection\",delimiter='\\t',header=None)\n",
    "df['encoded_labels']= df[0].map(lambda x: 1 if x=='spam' else 0).values\n",
    "X_train_raw,X_test_raw,y_train,y_test = train_test_split(df[1],df['encoded_labels'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "predictions = classifier.predict_proba(X_test)\n",
    "false_positive_rate,recall,thresholds = roc_curve(y_test,predictions[:,1])\n",
    "roc_auc = auc(false_positive_rate,recall)\n",
    "plt.title('Receive Operating Characteristic')\n",
    "plt.plot(false_positive_rate,recall,'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search就是用来确定最优超参数得方法，原理就是选取可能的参数不断运行模型获取最佳效果，网格搜索用的是穷举法，其缺点在于即使每个超参数的取值范围都很小，计算量也是巨大的。不过这是一个并行问题，参数与参数彼此独立，计算过程不需要同步，所以有很多方法解决这个问题。scikit-learn有GridSearchCV()函数解决这个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n"
     ]
    },
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A7A050D4EF5479D90307064A128D331']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A7A050D4EF5479D90307064A128D331'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.If object>], cell_name='<ipython-input-23-d60d91ed8f9e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>\n        result = <ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>, result=<ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-23-d60d91ed8f9e> in <module>()\n     17     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,\n     18     verbose=1, scoring='accuracy', cv=3) #这里n_jobs=-1告诉grid search要自动识别机器有几个核，并使用所有的核并行跑程序\n     19     df = pd.read_csv(r\"./some datasets/SMSSpamCollection\",delimiter='\\t',header=None)\n     20     X,y = df[1],df[0]\n     21     X_train_raw,X_test_raw,y_train,y_test = train_test_split(X,y)\n---> 22     grid_search.fit(X_train, y_train)\n     23     print ('Best score: %0.3f' % grid_search.best_score_)\n     24     print ('Best parameters set:')\n     25     best_parameters = grid_search.best_estimator_.get_params()\n     26     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...jobs', refit=True, scoring='accuracy', verbose=1), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object\n        self.param_grid = {'clf__C': (0.01, 0.1, 1, 10), 'clf__penalty': ('l1', 'l2'), 'vect__max_df': (0.25, 0.5, 0.75), 'vect__max_features': (2500, 5000, 10000, None), 'vect__ngram_range': ((1, 1), (1, 2)), 'vect__norm': ('l1', 'l2'), 'vect__stop_words': ('english', None), 'vect__use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...jobs', refit=True, scoring='accuracy', verbose=1), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon Jan 29 11:30:18 2018\nPID: 3732                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, scorer=make_scorer(accuracy_score), train=array([1304, 1306, 1309, ..., 4176, 4177, 4178]), test=array([   0,    1,    2, ..., 1402, 1403, 1404]), verbose=1, parameters={'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object)\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(doc=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(x=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    202         else:\n    203             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    204                              self.strip_accents)\n    205 \n    206         if self.lowercase:\n--> 207             return lambda x: strip_accents(x.lower())\n        x = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    208         else:\n    209             return strip_accents\n    210 \n    211     def build_tokenizer(self):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py in __getattr__(self=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, attr='lower')\n    571         elif attr == 'imag':\n    572             return self._imag()\n    573         elif attr == 'size':\n    574             return self.getnnz()\n    575         else:\n--> 576             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    577 \n    578     def transpose(self, axes=None, copy=False):\n    579         \"\"\"\n    580         Reverses the dimensions of the sparse matrix.\n\nAttributeError: lower not found\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1665, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 268, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 234, in _fit\n    Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1352, in fit_transform\n    X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 839, in fit_transform\n    self.fixed_vocabulary_)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 762, in _count_vocab\n    for feature in analyze(doc):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 241, in <lambda>\n    tokenize(preprocess(self.decode(doc))), stop_words)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 207, in <lambda>\n    return lambda x: strip_accents(x.lower())\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\", line 576, in __getattr__\n    raise AttributeError(attr + \" not found\")\nAttributeError: lower not found\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon Jan 29 11:30:18 2018\nPID: 3732                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, scorer=make_scorer(accuracy_score), train=array([1304, 1306, 1309, ..., 4176, 4177, 4178]), test=array([   0,    1,    2, ..., 1402, 1403, 1404]), verbose=1, parameters={'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object)\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(doc=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(x=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    202         else:\n    203             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    204                              self.strip_accents)\n    205 \n    206         if self.lowercase:\n--> 207             return lambda x: strip_accents(x.lower())\n        x = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    208         else:\n    209             return strip_accents\n    210 \n    211     def build_tokenizer(self):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py in __getattr__(self=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, attr='lower')\n    571         elif attr == 'imag':\n    572             return self._imag()\n    573         elif attr == 'size':\n    574             return self.getnnz()\n    575         else:\n--> 576             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    577 \n    578     def transpose(self, axes=None, copy=False):\n    579         \"\"\"\n    580         Reverses the dimensions of the sparse matrix.\n\nAttributeError: lower not found\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nAttributeError                                     Mon Jan 29 11:30:18 2018\nPID: 3732                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, scorer=make_scorer(accuracy_score), train=array([1304, 1306, 1309, ..., 4176, 4177, 4178]), test=array([   0,    1,    2, ..., 1402, 1403, 1404]), verbose=1, parameters={'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object)\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(doc=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(x=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    202         else:\n    203             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    204                              self.strip_accents)\n    205 \n    206         if self.lowercase:\n--> 207             return lambda x: strip_accents(x.lower())\n        x = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    208         else:\n    209             return strip_accents\n    210 \n    211     def build_tokenizer(self):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py in __getattr__(self=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, attr='lower')\n    571         elif attr == 'imag':\n    572             return self._imag()\n    573         elif attr == 'size':\n    574             return self.getnnz()\n    575         else:\n--> 576             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    577 \n    578     def transpose(self, axes=None, copy=False):\n    579         \"\"\"\n    580         Reverses the dimensions of the sparse matrix.\n\nAttributeError: lower not found\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d60d91ed8f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mX_train_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A7A050D4EF5479D90307064A128D331']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A7A050D4EF5479D90307064A128D331'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T11:30:16.114282', 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '36567C6AC35F469998A628E6B523DE6E', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.If object>], cell_name='<ipython-input-23-d60d91ed8f9e>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>\n        result = <ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>, result=<ExecutionResult object at 1fca4ce7518, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FCA6AA4540, file \"<ipython-input-23-d60d91ed8f9e>\", line 16>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-23-d60d91ed8f9e> in <module>()\n     17     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,\n     18     verbose=1, scoring='accuracy', cv=3) #这里n_jobs=-1告诉grid search要自动识别机器有几个核，并使用所有的核并行跑程序\n     19     df = pd.read_csv(r\"./some datasets/SMSSpamCollection\",delimiter='\\t',header=None)\n     20     X,y = df[1],df[0]\n     21     X_train_raw,X_test_raw,y_train,y_test = train_test_split(X,y)\n---> 22     grid_search.fit(X_train, y_train)\n     23     print ('Best score: %0.3f' % grid_search.best_score_)\n     24     print ('Best parameters set:')\n     25     best_parameters = grid_search.best_estimator_.get_params()\n     26     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...jobs', refit=True, scoring='accuracy', verbose=1), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object\n        self.param_grid = {'clf__C': (0.01, 0.1, 1, 10), 'clf__penalty': ('l1', 'l2'), 'vect__max_df': (0.25, 0.5, 0.75), 'vect__max_features': (2500, 5000, 10000, None), 'vect__ngram_range': ((1, 1), (1, 2)), 'vect__norm': ('l1', 'l2'), 'vect__stop_words': ('english', None), 'vect__use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...jobs', refit=True, scoring='accuracy', verbose=1), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Mon Jan 29 11:30:18 2018\nPID: 3732                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, make_scorer(accuracy_score), array([1304, 1306, 1309, ..., 4176, 4177, 4178]), array([   0,    1,    2, ..., 1402, 1403, 1404]), 1, {'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=2577     ham\n2605     ham\n469      ham\n5302     ...538      ham\nName: 0, Length: 4179, dtype: object, scorer=make_scorer(accuracy_score), train=array([1304, 1306, 1309, ..., 4176, 4177, 4178]), test=array([   0,    1,    2, ..., 1402, 1403, 1404]), verbose=1, parameters={'clf__C': 0.01, 'clf__penalty': 'l1', 'vect__max_df': 0.25, 'vect__max_features': 2500, 'vect__ngram_range': (1, 1), 'vect__norm': 'l1', 'vect__stop_words': 'english', 'vect__use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y_train = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    263         Returns\n    264         -------\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n--> 268         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(steps=[(....0001,\n          verbose=0, warm_start=False))])>\n        X = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n    269         if self._final_estimator is not None:\n    270             self._final_estimator.fit(Xt, y, **fit_params)\n    271         return self\n    272 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object, **fit_params={})\n    229         Xt = X\n    230         for name, transform in self.steps[:-1]:\n    231             if transform is None:\n    232                 pass\n    233             elif hasattr(transform, \"fit_transform\"):\n--> 234                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n        transform.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        y = 5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    235             else:\n    236                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    237                               .transform(Xt)\n    238         if self._final_estimator is None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=5196    spam\n1217    spam\n1460    spam\n2248    s...538      ham\nName: 0, Length: 2786, dtype: object)\n   1347         Returns\n   1348         -------\n   1349         X : sparse matrix, [n_samples, n_features]\n   1350             Tf-idf-weighted document-term matrix.\n   1351         \"\"\"\n-> 1352         X = super(TfidfVectorizer, self).fit_transform(raw_documents)\n        X = undefined\n        self.fit_transform = <bound method TfidfVectorizer.fit_transform of T...zer=None, use_idf=True,\n        vocabulary=None)>\n        raw_documents = <2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>\n   1353         self._tfidf.fit(X)\n   1354         # X is already a transformed view of raw_documents so\n   1355         # we set copy to False\n   1356         return self._tfidf.transform(X, copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, y=None)\n    834         max_df = self.max_df\n    835         min_df = self.min_df\n    836         max_features = self.max_features\n    837 \n    838         vocabulary, X = self._count_vocab(raw_documents,\n--> 839                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    840 \n    841         if self.binary:\n    842             X.data.fill(1)\n    843 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=TfidfVectorizer(analyzer='word', binary=False, d...izer=None, use_idf=True,\n        vocabulary=None), raw_documents=<2786x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, fixed_vocab=False)\n    757         indptr = _make_int_array()\n    758         values = _make_int_array()\n    759         indptr.append(0)\n    760         for doc in raw_documents:\n    761             feature_counter = {}\n--> 762             for feature in analyze(doc):\n        feature = undefined\n        analyze = <function VectorizerMixin.build_analyzer.<locals>.<lambda>>\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    763                 try:\n    764                     feature_idx = vocabulary[feature]\n    765                     if feature_idx not in feature_counter:\n    766                         feature_counter[feature_idx] = 1\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(doc=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    236         elif self.analyzer == 'word':\n    237             stop_words = self.get_stop_words()\n    238             tokenize = self.build_tokenizer()\n    239 \n    240             return lambda doc: self._word_ngrams(\n--> 241                 tokenize(preprocess(self.decode(doc))), stop_words)\n        doc = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n    242 \n    243         else:\n    244             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n    245                              self.analyzer)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in <lambda>(x=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>)\n    202         else:\n    203             raise ValueError('Invalid value for \"strip_accents\": %s' %\n    204                              self.strip_accents)\n    205 \n    206         if self.lowercase:\n--> 207             return lambda x: strip_accents(x.lower())\n        x = <1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>\n        x.lower = undefined\n    208         else:\n    209             return strip_accents\n    210 \n    211     def build_tokenizer(self):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py in __getattr__(self=<1x7512 sparse matrix of type '<class 'numpy.flo... stored elements in Compressed Sparse Row format>, attr='lower')\n    571         elif attr == 'imag':\n    572             return self._imag()\n    573         elif attr == 'size':\n    574             return self.getnnz()\n    575         else:\n--> 576             raise AttributeError(attr + \" not found\")\n        attr = 'lower'\n    577 \n    578     def transpose(self, axes=None, copy=False):\n    579         \"\"\"\n    580         Reverses the dimensions of the sparse matrix.\n\nAttributeError: lower not found\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    " 'vect__max_df': (0.25, 0.5, 0.75),\n",
    " 'vect__stop_words': ('english', None),\n",
    " 'vect__max_features': (2500, 5000, 10000, None),\n",
    " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
    " 'vect__use_idf': (True, False),\n",
    " 'vect__norm': ('l1', 'l2'),\n",
    " 'clf__penalty': ('l1', 'l2'),\n",
    " 'clf__C': (0.01, 0.1, 1, 10),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,\n",
    "    verbose=1, scoring='accuracy', cv=3) #这里n_jobs=-1告诉grid search要自动识别机器有几个核，并使用所有的核并行跑程序\n",
    "    df = pd.read_csv(r\"./some datasets/SMSSpamCollection\",delimiter='\\t',header=None)\n",
    "    X,y = df[1],df[0]\n",
    "    X_train_raw,X_test_raw,y_train,y_test = train_test_split(X,y)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print ('Best score: %0.3f' % grid_search.best_score_)\n",
    "    print ('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r'%(param_name, best_parameters[param_name]))\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "    print('Precision:', precision_score(y_test, predictions))\n",
    "    print('Recall:', recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification多类分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn用one-vs.-all或one-vs.-the-rest方法实现多类分类，就是把多类中的每个类都作为二元分类处理。分类器预测样本不同类型，将具有最大置信水平的类型作为样本类型。LogisticRegression()通过one-vs.-all策略支持多类分类。\n",
    "\n",
    "本例中，我们利用烂番茄（Rotten Tomatoes）网站影评短语数据对电影进行评价。每个影评可以归入下面5个类项：不给力（negative），不太给力（somewhat negative），中等（neutral），有点给力（somewhat positive）, 给力（positive）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "#压缩节省空间\n",
    "z = zipfile.ZipFile('./some datasets/train.tsv.zip')\n",
    "df = pd.read_csv(z.open(z.namelist()[0]),header=0,delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      156060\n",
       "SentenceId    156060\n",
       "Phrase        156060\n",
       "Sentiment     156060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A series of escapades demonstrating the adage ...\n",
       "1    A series of escapades demonstrating the adage ...\n",
       "2                                             A series\n",
       "3                                                    A\n",
       "4                                               series\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    156060.000000\n",
       "mean          2.063578\n",
       "std           0.893832\n",
       "min           0.000000\n",
       "25%           2.000000\n",
       "50%           2.000000\n",
       "75%           3.000000\n",
       "max           4.000000\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.509945\n",
       "3    0.210989\n",
       "1    0.174760\n",
       "4    0.058990\n",
       "0    0.045316\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()/df.Sentiment.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A7A050D4EF5479D90307064A128D331']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A7A050D4EF5479D90307064A128D331'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.FunctionDef object>, <_ast.If object>], cell_name='<ipython-input-33-163cdae9aa8f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>\n        result = <ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>, result=<ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 25:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  , 26: PhraseId      156060\nSentenceId    156060\nPhrase        156060\nSentiment     156060\ndtype: int64, 27: 0    A series of escapades demonstrating the ada...               series\nName: Phrase, dtype: object, 29: count    156060.000000\nmean          2.063578\nst...         4.000000\nName: Sentiment, dtype: float64, 30: 2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64, 31: 2    0.509945\n3    0.210989\n1    0.174760\n4    0...990\n0    0.045316\nName: Sentiment, dtype: float64}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 25:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  , 26: PhraseId      156060\nSentenceId    156060\nPhrase        156060\nSentiment     156060\ndtype: int64, 27: 0    A series of escapades demonstrating the ada...               series\nName: Phrase, dtype: object, 29: count    156060.000000\nmean          2.063578\nst...         4.000000\nName: Sentiment, dtype: float64, 30: 2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64, 31: 2    0.509945\n3    0.210989\n1    0.174760\n4    0...990\n0    0.045316\nName: Sentiment, dtype: float64}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-33-163cdae9aa8f> in <module>()\n     30     best_parameters = grid_search.best_estimator_.get_params()\n     31     for param_name in sorted(parameters.keys()):\n     32         print('\\t%s: %r' %(param_name,best_parameters[param_name]))\n     33 \n     34 if __name__=='__main__':\n---> 35     main()\n     36 \n     37 \n     38 \n     39 \n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-33-163cdae9aa8f> in main()\n     22     z = zipfile.ZipFile('./some datasets/train.tsv.zip')\n     23     df = pd.read_csv(z.open(z.namelist()[0]),header=0,delimiter='\\t')\n     24     X,y = df['Phrase'],df['Sentiment'].as_matrix()\n     25     X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.5)\n     26     grid_search = GridSearchCV(pipeline,parameters,n_jobs=3,verbose=1,scoring='accuracy')\n---> 27     grid_search.fit(X_train,y_train)\n     28     print('Best score: %0.3f'% grid_search.best_score_)\n     29     print('Best parameters set:')\n     30     best_parameters = grid_search.best_estimator_.get_params()\n     31     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object\n        y = array([2, 4, 2, ..., 2, 3, 2], dtype=int64)\n        self.param_grid = {'clf_c': (0.1, 1, 10), 'vect_max_df': (0.25, 0.5), 'vect_ngram_range': ((1, 1), (1, 2)), 'vect_use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 14:21:06 2018\nPID: 5228                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), scorer=make_scorer(accuracy_score), train=array([25666, 25668, 25672, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 26323, 26345, 26356]), verbose=1, parameters={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_c'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_c for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1654, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 180, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 69, in _set_params\n    super(_BasePipeline, self).set_params(**params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 291, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter clf_c for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 14:21:06 2018\nPID: 5228                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), scorer=make_scorer(accuracy_score), train=array([25666, 25668, 25672, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 26323, 26345, 26356]), verbose=1, parameters={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_c'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_c for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 14:21:06 2018\nPID: 5228                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), scorer=make_scorer(accuracy_score), train=array([25666, 25668, 25672, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 26323, 26345, 26356]), verbose=1, parameters={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_c'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_c for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-163cdae9aa8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-163cdae9aa8f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score: %0.3f'\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC9EF89B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A7A050D4EF5479D90307064A128D331']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A7A050D4EF5479D90307064A128D331'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T14:20:57.432807', 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'session': '1A7A050D4EF5479D90307064A128D331', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9ACF52F94E4D4DB08FEA19ED659491DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"import pandas as pd\\nfrom sklearn.feature_extract...aram_name]))\\n\\nif __name__=='__main__':\\n    main()\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.FunctionDef object>, <_ast.If object>], cell_name='<ipython-input-33-163cdae9aa8f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>\n        result = <ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>, result=<ExecutionResult object at 1fca90de4e0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FCA90BBC00, file \"<ipython-input-33-163cdae9aa8f>\", line 34>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 25:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  , 26: PhraseId      156060\nSentenceId    156060\nPhrase        156060\nSentiment     156060\ndtype: int64, 27: 0    A series of escapades demonstrating the ada...               series\nName: Phrase, dtype: object, 29: count    156060.000000\nmean          2.063578\nst...         4.000000\nName: Sentiment, dtype: float64, 30: 2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64, 31: 2    0.509945\n3    0.210989\n1    0.174760\n4    0...990\n0    0.045316\nName: Sentiment, dtype: float64}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...Collection\",delimiter=\\'\\\\t\\',header=None)\\ndf.head()', \"df['encoded_labels']= df[1].map(lambda x: 1 if x=='spam' else 0).values\\ndf.head()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...l('Recall')\\n# plt.xlabel('Fall-out')\\n# plt.show()\", 'df', \"import numpy as np\\nimport pandas as pd\\nimport ma...label('Recall')\\nplt.xlabel('Fall-out')\\nplt.show()\", 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', 'import pandas as pd\\nfrom sklearn.feature_extract...mport precision_score,recall_score,accuracy_score', \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...y':('11','12'),\\n    'clf_c':(0.01,0.1,1,10)    \\n}\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...                                                 \", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...print('Recall:',recall_score(y_test,predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...nt ('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect',TfidfVectorize...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n('vect', TfidfVectorizer(s...int('Recall:', recall_score(y_test, predictions))\", \"pipeline = Pipeline([\\n    ('vect', TfidfVectoriz...int('Recall:', recall_score(y_test, predictions))\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {1:       0                                         ...Nah I don't think he goes to usf, he lives aro..., 2:       0                                         ...k he goes to usf, he lives aro...               0, 5:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 7:          0                                      ...its name               0\n\n[5572 rows x 3 columns], 25:    PhraseId  SentenceId                         ... 2  \n2          2  \n3          2  \n4          2  , 26: PhraseId      156060\nSentenceId    156060\nPhrase        156060\nSentiment     156060\ndtype: int64, 27: 0    A series of escapades demonstrating the ada...               series\nName: Phrase, dtype: object, 29: count    156060.000000\nmean          2.063578\nst...         4.000000\nName: Sentiment, dtype: float64, 30: 2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64, 31: 2    0.509945\n3    0.210989\n1    0.174760\n4    0...990\n0    0.045316\nName: Sentiment, dtype: float64}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, 'X': 0       Go until jurong point, crazy.. Available... to its name\nName: 1, Length: 5572, dtype: object, 'X_test': <1393x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, 'X_test_raw': 2430    Guess who am I?This is the first time I ...ntury cm ...\nName: 1, Length: 1393, dtype: object, 'X_train': <4179x7512 sparse matrix of type '<class 'numpy.... stored elements in Compressed Sparse Row format>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-33-163cdae9aa8f> in <module>()\n     30     best_parameters = grid_search.best_estimator_.get_params()\n     31     for param_name in sorted(parameters.keys()):\n     32         print('\\t%s: %r' %(param_name,best_parameters[param_name]))\n     33 \n     34 if __name__=='__main__':\n---> 35     main()\n     36 \n     37 \n     38 \n     39 \n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-33-163cdae9aa8f> in main()\n     22     z = zipfile.ZipFile('./some datasets/train.tsv.zip')\n     23     df = pd.read_csv(z.open(z.namelist()[0]),header=0,delimiter='\\t')\n     24     X,y = df['Phrase'],df['Sentiment'].as_matrix()\n     25     X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.5)\n     26     grid_search = GridSearchCV(pipeline,parameters,n_jobs=3,verbose=1,scoring='accuracy')\n---> 27     grid_search.fit(X_train,y_train)\n     28     print('Best score: %0.3f'% grid_search.best_score_)\n     29     print('Best parameters set:')\n     30     best_parameters = grid_search.best_estimator_.get_params()\n     31     for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...obs', refit=True, scoring='accuracy', verbose=1)>\n        X = 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object\n        y = array([2, 4, 2, ..., 2, 3, 2], dtype=int64)\n        self.param_grid = {'clf_c': (0.1, 1, 10), 'vect_max_df': (0.25, 0.5), 'vect_ngram_range': ((1, 1), (1, 2)), 'vect_use_idf': (True, False)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...jobs', refit=True, scoring='accuracy', verbose=1), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 14:21:06 2018\nPID: 5228                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), 36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, array([2, 4, 2, ..., 2, 3, 2], dtype=int64), make_scorer(accuracy_score), array([25666, 25668, 25672, ..., 78027, 78028, 78029]), array([    0,     1,     2, ..., 26323, 26345, 26356]), 1, {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), X=36942                                           ...ltures\nName: Phrase, Length: 78030, dtype: object, y=array([2, 4, 2, ..., 2, 3, 2], dtype=int64), scorer=make_scorer(accuracy_score), train=array([25666, 25668, 25672, ..., 78027, 78028, 78029]), test=array([    0,     1,     2, ..., 26323, 26345, 26356]), verbose=1, parameters={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        parameters = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **kwargs={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel....0001,\n          verbose=0, warm_start=False))])>\n        kwargs = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), steps_attr='steps', **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st....0001,\n          verbose=0, warm_start=False))])>\n        params = {'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('vect', TfidfVectorizer(analyze...0.0001,\n          verbose=0, warm_start=False))]), **params={'clf_c': 0.1, 'vect_max_df': 0.25, 'vect_ngram_range': (1, 1), 'vect_use_idf': True})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_c'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_c for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import zipfile\n",
    "\n",
    "def main():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect',TfidfVectorizer(stop_words='english')),\n",
    "        ('clf',LogisticRegression())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect_max_df':(0.25,0.5),\n",
    "        'vect_ngram_range':((1,1),(1,2)),\n",
    "        'vect_use_idf':(True,False),\n",
    "        'clf_c':(0.1,1,10),\n",
    "    }\n",
    "\n",
    "    z = zipfile.ZipFile('./some datasets/train.tsv.zip')\n",
    "    df = pd.read_csv(z.open(z.namelist()[0]),header=0,delimiter='\\t')\n",
    "    X,y = df['Phrase'],df['Sentiment'].as_matrix()\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.5)\n",
    "    grid_search = GridSearchCV(pipeline,parameters,n_jobs=3,verbose=1,scoring='accuracy')\n",
    "    grid_search.fit(X_train,y_train)\n",
    "    print('Best score: %0.3f'% grid_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' %(param_name,best_parameters[param_name]))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多标签分类转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.5\n",
      "1.0\n",
      "0.75\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, jaccard_similarity_score\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]])))\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]])))\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "101px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
