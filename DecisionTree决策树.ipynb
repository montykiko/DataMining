{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章我们要讨论一种\n",
    "简单的非线性模型，用来解决回归与分类问题，称为决策树（decision tree）。首先，我们将用决策\n",
    "树做一个广告屏蔽器，可以将网页中的广告内容屏蔽掉。之后，我们介绍集成学习（lensemble\n",
    "learning）方法，通过将一系列学习方法集成使用，以取得更好的训练效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集：http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过类型的比例并不协调，459幅广告图片，2820幅正常内容。决\n",
    "策树学习算法可以从比例并不协调的数据集中生成一个不平衡的决策树（biased tree）。在决定是否\n",
    "值得通过过抽样（over-sampling）和欠抽样（under-sampling）的方法平衡训练集之前，我们将用\n",
    "不相关的数据集对模型进行评估。本例的解释变量就是图片的尺寸，网址链接里的单词，以及图片标\n",
    "签周围的单词。响应变量就是图片的类型。解释变量已经被转换成特征向量了。前三个特征值表示宽\n",
    "度，高度，图像纵横比（aspect ratio）。剩下的特征是文本变量的二元频率值。下面，我们用网格\n",
    "搜索来确定决策树模型最大最优评价效果（F1 score）的超参数，然后把决策树用在测试集进行效果\n",
    "评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import zipfile\n",
    "z = zipfile.ZipFile('./some datasets/ad-dataset.zip')\n",
    "df = pd.read_csv(z.open(z.namelist()[0]),header=None,low_memory=False)\n",
    "explanatory_variable_columns = set(df.columns.values)\n",
    "response_variable_column = df[len(df.columns.values)-1]\n",
    "explanatory_variable_columns.remove(len(df.columns.values)-1)\n",
    "\n",
    "y = [1 if e=='ad.' else 0 for e in response_variable_column]\n",
    "X = df.loc[:,list(explanatory_variable_columns )]\n",
    "\n",
    "X.replace(to_replace=' *\\?',value=-1,regex=True,inplace=True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf',DecisionTreeClassifier(criterion='entropy'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf_max_depth':(150,155,160),\n",
    "    'clf_min_samples_split':(1,2,3),\n",
    "    'clf_min_samples_leaf':(1,2,3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'57F0E843C94C4E0D8958EC2FC4806FB5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'57F0E843C94C4E0D8958EC2FC4806FB5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.For object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-11-d52209dae9d4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>\n        result = <ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>, result=<ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], '_3': <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], '_3': <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-11-d52209dae9d4> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n      6 grid_search.fit(X_train,y_train)\n      7 print('Best score: %0.3f' % grid_search.best_score_)\n      8 print('Best parameters set:')\n      9 best_parameters = grid_search.best_estimator_.get_params()\n     10 for param_name in sorted(parameters.keys()):\n     11     print('\\t%s: %r' % (param_name,best_parameters[param_name]))\n     12 predictions = grid_search.predict(X_test)\n     13 print(classification_report(y_test,predictions))\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...]\n        self.param_grid = {'clf_max_depth': (150, 155, 160), 'clf_min_samples_leaf': (1, 2, 3), 'clf_min_samples_split': (1, 2, 3)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 15:08:01 2018\nPID: 8184                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 818,  819,  820, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), verbose=1, parameters={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        parameters = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **kwargs={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...rt=False, random_state=None, splitter='best'))])>\n        kwargs = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), steps_attr='steps', **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        params = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1654, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 180, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 69, in _set_params\n    super(_BasePipeline, self).set_params(**params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 291, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter clf_max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 15:08:01 2018\nPID: 8184                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 818,  819,  820, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), verbose=1, parameters={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        parameters = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **kwargs={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...rt=False, random_state=None, splitter='best'))])>\n        kwargs = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), steps_attr='steps', **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        params = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 15:08:01 2018\nPID: 8184                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 818,  819,  820, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), verbose=1, parameters={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        parameters = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **kwargs={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...rt=False, random_state=None, splitter='best'))])>\n        kwargs = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), steps_attr='steps', **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        params = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d52209dae9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'57F0E843C94C4E0D8958EC2FC4806FB5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'57F0E843C94C4E0D8958EC2FC4806FB5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:07:59.538766', 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7467D413551C405FBF7C5DEEEB6624DB', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.For object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-11-d52209dae9d4>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>\n        result = <ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>, result=<ExecutionResult object at 2a82aeb55c0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A82AE42150, file \"<ipython-input-11-d52209dae9d4>\", line 2>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], '_3': <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], '_3': <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-11-d52209dae9d4> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n      6 grid_search.fit(X_train,y_train)\n      7 print('Best score: %0.3f' % grid_search.best_score_)\n      8 print('Best parameters set:')\n      9 best_parameters = grid_search.best_estimator_.get_params()\n     10 for param_name in sorted(parameters.keys()):\n     11     print('\\t%s: %r' % (param_name,best_parameters[param_name]))\n     12 predictions = grid_search.predict(X_test)\n     13 print(classification_report(y_test,predictions))\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...]\n        self.param_grid = {'clf_max_depth': (150, 155, 160), 'clf_min_samples_leaf': (1, 2, 3), 'clf_min_samples_split': (1, 2, 3)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 15:08:01 2018\nPID: 8184                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], make_scorer(f1_score), array([ 818,  819,  820, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), 1, {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...], scorer=make_scorer(f1_score), train=array([ 818,  819,  820, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 813, 814, 815, 816, 817, 823,\n       824, 839]), verbose=1, parameters={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1649     fit_params = fit_params if fit_params is not None else {}\n   1650     fit_params = dict([(k, _index_param_value(X, v, train))\n   1651                       for k, v in fit_params.items()])\n   1652 \n   1653     if parameters is not None:\n-> 1654         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        parameters = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n   1655 \n   1656     start_time = time.time()\n   1657 \n   1658     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **kwargs={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...rt=False, random_state=None, splitter='best'))])>\n        kwargs = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), steps_attr='steps', **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...rt=False, random_state=None, splitter='best'))])>\n        params = {'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(steps=[('clf', DecisionTreeClassifier(c...ort=False, random_state=None, splitter='best'))]), **params={'clf_max_depth': 150, 'clf_min_samples_leaf': 1, 'clf_min_samples_split': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'clf_max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter clf_max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name,best_parameters[param_name]))\n",
    "predictions = grid_search.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集成学习方法将一堆模型组合起来使用，比单个模型可以获取更好的效果。随机森林（random\n",
    "forest）是一种随机选取训练集解释变量的子集进行训练，获得一系列决策树的集合的方法。随机森\n",
    "林通常用其决策树集合里每个决策树的预测结果的均值或众数作为最终预测值。scikit-learn里的随机\n",
    "森林使用均值作为预测值。随机森林相比单一决策树，不太会受到拟合过度的影响，因为随机森林的\n",
    "每个决策树都看不到训练集的全貌，只是训练一部分解释变量数据，不会记忆训练集的全部噪声。\n",
    "下面我们用随机森林升级我们的广告屏蔽程序。把前面用的DecisionTreeClassifier替换\n",
    "成RandomForestClassifier就可以了。和前面一样，我们仍然用网格搜索来探索最优超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'57F0E843C94C4E0D8958EC2FC4806FB5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'57F0E843C94C4E0D8958EC2FC4806FB5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, ...], cell_name='<ipython-input-12-ad60a8531b24>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>\n        result = <ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>, result=<ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-12-ad60a8531b24> in <module>()\n     26 'clf__min_samples_split': (1, 2, 3),\n     27 'clf__min_samples_leaf': (1, 2, 3)\n     28 }\n     29 \n     30 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n---> 31 grid_search.fit(X_train,y_train)\n     32 print('Best score: %0.3f' % grid_search.best_score_)\n     33 print('Best parameters set:')\n     34 best_parameters = grid_search.best_estimator_.get_params()\n     35 for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...]\n        self.param_grid = {'clf__max_depth': (50, 150, 250), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3), 'clf__n_estimators': (5, 10, 20, 50)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 15:14:07 2018\nPID: 7944                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], scorer=make_scorer(f1_score), train=array([ 804,  808,  809, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=240256376, splitter='best')>\n        X = array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  3.,  0., ...,  2.,  2.,  0.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1665, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 270, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 326, in fit\n    for i, t in enumerate(trees))\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 758, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 608, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 571, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 109, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 326, in __init__\n    self.results = batch()\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 120, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 739, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 199, in fit\n    % self.min_samples_split)\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 15:14:07 2018\nPID: 7944                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], scorer=make_scorer(f1_score), train=array([ 804,  808,  809, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=240256376, splitter='best')>\n        X = array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  3.,  0., ...,  2.,  2.,  0.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jan 29 15:14:07 2018\nPID: 7944                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], scorer=make_scorer(f1_score), train=array([ 804,  808,  809, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=240256376, splitter='best')>\n        X = array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  3.,  0., ...,  2.,  2.,  0.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ad60a8531b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \"\"\"\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 for train, test in cv)\n\u001b[1;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A8254A9B70, fil...lib\\site-packages\\ipykernel\\__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__pycache__\\__main__.cpython-36.pyc', '__doc__': None, '__file__': r'C:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...da3\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\K...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'57F0E843C94C4E0D8958EC2FC4806FB5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'57F0E843C94C4E0D8958EC2FC4806FB5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-01-29T15:14:04.715188', 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'session': '57F0E843C94C4E0D8958EC2FC4806FB5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '711D2C4821AC4ED18EC7E667C2123D42', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))',), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, ...], cell_name='<ipython-input-12-ad60a8531b24>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>\n        result = <ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>, result=<ExecutionResult object at 2a827834160, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A82AF3D4B0, file \"<ipython-input-12-ad60a8531b24>\", line 31>\n        self.user_global_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], ...}\n        self.user_ns = {'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'import pandas as pd\\nfrom sklearn.tree import Dec...X = df.loc[:,list(explanatory_variable_columns )]', 'X', 'y', r\"X.replace(to_replace=' *\\?',value=-1,regex=True,...ain,X_test,y_train,y_test = train_test_split(X,y)\", \"pipeline = Pipeline([\\n    ('clf',DecisionTreeClassifier(criterion='entropy'))\\n])\", \"parameters = {\\n    'clf_max_depth':(150,155,160)...it':(1,2,3),\\n    'clf_min_samples_leaf':(1,2,3)\\n}\", 'grid_search = GridSearchCV(pipeline,parameters,n...\\nprint(classification_report(y_test,predictions))', 'import pandas as pd\\nfrom sklearn.cross_validatio...\\nprint(classification_report(y_test,predictions))'], 'Out': {3: <zipfile.ZipFile filename='./some datasets/ad-dataset.zip' mode='r'>, 6:       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 7: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...]}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'X':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[3279 rows x 1558 columns], 'X_test':       0     1       2    3     4     5     6    ... 0     0     0     0  \n\n[820 rows x 1558 columns], 'X_train':       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], '_': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...], ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Kismet\\Documents\\我的坚果云\\Git\\git_repository\\DataMining\\<ipython-input-12-ad60a8531b24> in <module>()\n     26 'clf__min_samples_split': (1, 2, 3),\n     27 'clf__min_samples_leaf': (1, 2, 3)\n     28 }\n     29 \n     30 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n---> 31 grid_search.fit(X_train,y_train)\n     32 print('Best score: %0.3f' % grid_search.best_score_)\n     33 print('Best parameters set:')\n     34 best_parameters = grid_search.best_estimator_.get_params()\n     35 for param_name in sorted(parameters.keys()):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...])\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='f1', verbose=1)>\n        X =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns]\n        y = [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...]\n        self.param_grid = {'clf__max_depth': (50, 150, 250), 'clf__min_samples_leaf': (1, 2, 3), 'clf__min_samples_split': (1, 2, 3), 'clf__n_estimators': (5, 10, 20, 50)}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring='f1', verbose=1), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jan 29 15:14:07 2018\nPID: 7944                Python 3.6.0: C:\\Users\\Kismet\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]),       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], make_scorer(f1_score), array([ 804,  808,  809, ..., 2456, 2457, 2458]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), 1, {'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[2459 rows x 1558 columns], y=[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...], scorer=make_scorer(f1_score), train=array([ 804,  808,  809, ..., 2456, 2457, 2458]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 843, 850, 852, 863, 868, 871,\n       885, 890]), verbose=1, parameters={'clf__max_depth': 50, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 1, 'clf__n_estimators': 5}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...one,\n            verbose=0, warm_start=False))])>\n        X_train =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y_train = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(steps=[('clf', RandomForestClassifier(b...None,\n            verbose=0, warm_start=False))]), X=      0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns], y=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None,\n            verbose=0, warm_start=False)>\n        Xt =       0     1       2    3     4     5     6    ...0     0     0     0  \n\n[1638 rows x 1558 columns]\n        y = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in fit(self=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 4\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), None, 0, 5)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _parallel_build_trees(tree=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), forest=RandomForestClassifier(bootstrap=True, class_wei...te=None,\n            verbose=0, warm_start=False), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=None, tree_idx=0, n_trees=5, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeClassifier.fit of Deci...=False, random_state=240256376, splitter='best')>\n        X = array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32)\n        y = array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  3.,  0., ...,  2.,  2.,  0.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    734 \n    735         super(DecisionTreeClassifier, self).fit(\n    736             X, y,\n    737             sample_weight=sample_weight,\n    738             check_input=check_input,\n--> 739             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n    740         return self\n    741 \n    742 \n    743     def predict_proba(self, X, check_input=True):\n\n...........................................................................\nC:\\Users\\Kismet\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in fit(self=DecisionTreeClassifier(class_weight=None, criter...t=False, random_state=240256376, splitter='best'), X=array([[  51.        ,  209.        ,    4.09800...      0.        ,    0.        ]], dtype=float32), y=array([[ 0.],\n       [ 0.],\n       [ 0.],\n       ..., \n       [ 0.],\n       [ 0.],\n       [ 0.]]), sample_weight=array([ 1.,  3.,  0., ...,  2.,  2.,  0.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import zipfile\n",
    "z = zipfile.ZipFile('./some datasets/ad-dataset.zip')\n",
    "df = pd.read_csv(z.open(z.namelist()[0]),header=None,low_memory=False)\n",
    "explanatory_variable_columns = set(df.columns.values)\n",
    "response_variable_column = df[len(df.columns.values)-1]\n",
    "explanatory_variable_columns.remove(len(df.columns.values)-1)\n",
    "\n",
    "y = [1 if e=='ad.' else 0 for e in response_variable_column]\n",
    "X = df.loc[:,list(explanatory_variable_columns )]\n",
    "X.replace(to_replace=' *\\?',value=-1,regex=True,inplace=True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "('clf', RandomForestClassifier(criterion='entropy'))\n",
    "])\n",
    "parameters = {\n",
    "'clf__n_estimators': (5, 10, 20, 50),\n",
    "'clf__max_depth': (50, 150, 250),\n",
    "'clf__min_samples_split': (1, 2, 3),\n",
    "'clf__min_samples_leaf': (1, 2, 3)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1,scoring='f1')\n",
    "grid_search.fit(X_train,y_train)\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name,best_parameters[param_name]))\n",
    "predictions = grid_search.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
